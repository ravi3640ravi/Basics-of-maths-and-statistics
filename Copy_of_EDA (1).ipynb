{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DShF1ZBX3XG4"
   },
   "source": [
    "# Chapter 1: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75LLoVJE37qQ"
   },
   "source": [
    "**Question: What is EDA?** \\\\\n",
    "Answer: Loosely speaking, any method of looking at the data that does not include statistical modelling and inference falls under EDA.\n",
    "  <br> \\\\\n",
    "**Question: Why EDA?** \\\\\n",
    "Answer: EDA is critical first step in analyzing data:\n",
    "\n",
    "\n",
    "*   Detection of mistakes\n",
    "*   Checking of assumptions\n",
    "*   Preliminary selection of models\n",
    "*   Determination of relationships between explanatory variables and outcome variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zm16rP6s55sD"
   },
   "source": [
    "##1.1 Typical Data Format and Types of EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULn2wqkU6cia"
   },
   "source": [
    "It starts with a research objective. Once the research objective is defined, experiment design is prepared and susequently data is collected. Data is categorized into two categories: \\\\\n",
    "\n",
    "*   Structured Data: Rectangular array, where each row is a subject and each column is the outcome variable of the experiment. Each column can be categorized into:\n",
    "    1.   Numerical Data (Quantitative)\n",
    "    *   Discrete Data: Countable values with no intermediate values between the data points. Example- No. of students in a class.\n",
    "    *   Continious Data: Can take any value with a range. Example: Height of employees within a department.\n",
    "\n",
    "  2.   Non-numerical Data (Qualitative/Categorical)\n",
    "  *   Nominal Data: Categories with no inherent order. Example- Gender, color etc.\n",
    "  *   Ordinal Data: Categories with a meaningful order but intervals between the data does not have a natural meaning. Example: Military ranks, education level etc.  \n",
    "\n",
    "*   Unstructured Data: Audio data, text data, video data etc\n",
    "\n",
    "*We will focus our attention on the structured data in this tutotial. Please see the second part of this tutorial for EDA on unstructured data, focus on text data.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQtBEWwDDxT2"
   },
   "source": [
    "Structured data are big in size (hundreads of rows and columns) and it is difficult for brain to make sense of such big data. EDA techniques are developed as an aid, which partially to fully hide certain aspect of the data and make the other aspects visible. \\\\\n",
    "EDA is cross-classified into two ways:\n",
    "*   Graphical and non-graphical\n",
    "*   Univariate and multivariate\n",
    "\n",
    "*One need not to follow the defined methods only, EDA could be very unique as per data and requirement. It is an experimental ground to play with data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzrDBy5SF7QQ"
   },
   "source": [
    "# 1.2 Univariate Non-graphical Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RV9Z21NfGh4i"
   },
   "source": [
    "Analysis done on the data of a particular variable for all the subjects is called univariate analysis. Measurements for this variable is called **Sample Distribution**, which in turn more or less represnt the **Population Distribution**.\n",
    "\n",
    "The goal of univariate non-graphical EDA is to better appreciate Sample Distribution, make tentative conculsions about Population Distribution and detect outliers from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMtS9LDiaS_J"
   },
   "source": [
    "## 1.3 Non-numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jaTm2pwarJX"
   },
   "source": [
    "The characteristics of interest for a non-numerical variable are simply the range of values and the frequency (or relative frequency) of occurrence for each value. Therefore the only useful univariate non-graphical techniques for categorical variables is some form of tabulation of the frequencies. \\\\\n",
    "*Note that it is useful to have the total count (frequency) to verify that we have an observation for each subject that we recruited.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "In5l1ONccXyM"
   },
   "source": [
    "## 1.4 Numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quhTslaCcmCy"
   },
   "source": [
    "Univariate EDA for a numerical variable is a way to make prelim-\n",
    "inary assessments about the population distribution\n",
    "using the observed sample. \\\\\n",
    "The characteristics of the population distribution are its center, spread, modality (number of peaks), shape (including “heaviness of the tails”), and outliers. \\\\\n",
    "Our observed data represent just one sample out of an inﬁnite number of possible samples. The characteristics of our randomly observed sample are not inherently interesting, except to the degree that they represent the population that it came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define a small, clear population\n",
    "population = [10, 12, 14, 16, 18, 20, 22, 24, 26, 28]\n",
    "\n",
    "# Representative sample: random sampling from entire population\n",
    "sample_representative = random.sample(population, k=5)\n",
    "\n",
    "# Non-representative sample: biased sampling (e.g., from upper end only)\n",
    "sample_non_representative = random.sample([20, 22, 24, 26, 28], k=5)\n",
    "\n",
    "# Output\n",
    "print(\"Population:                 \", population)\n",
    "print(\"Representative Sample:      \", sample_representative)\n",
    "print(\"Non-Representative Sample:  \", sample_non_representative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26dLAyYJcCEQ"
   },
   "source": [
    "**Sample Statistics** from data, such as **Sample Mean**, **Sample Variance**, **Sample Standard Deviation**, **Sample Skewness** and **Sample Kurtosis** etc vary from sample to sample and provide some uncertain information about Population Parameter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def describe(data, name):\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"  Mean:               {np.mean(data):.2f}\")\n",
    "    print(f\"  Median:             {np.median(data):.2f}\")\n",
    "    print(f\"  Std Dev (sample):   {np.std(data, ddof=1):.2f}\")\n",
    "    print(f\"  Std Dev (pop):      {np.std(data, ddof=0):.2f}\")\n",
    "    print(f\"  Range:              {max(data) - min(data)}\")\n",
    "    print(f\"  Skewness:           {skew(data):.2f}\")\n",
    "    print(f\"  Kurtosis:           {kurtosis(data):.2f}\")\n",
    "\n",
    "# Results\n",
    "describe(population, \"Population\")\n",
    "describe(sample_representative, \"Representative Sample\")\n",
    "describe(sample_non_representative, \"Non-Representative Sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4vMilSCvtH-"
   },
   "source": [
    "Samples Statistics are best thought of as random (non-ﬁxed) **Estimates** of the ﬁxed, unknown Population Parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNPHbRfgxGW7"
   },
   "source": [
    "## 1.5 Central Tendency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ML5k_3PxMTW"
   },
   "source": [
    "The central tendency refers to typical or middle values of a variable. The common, useful measures of central tendency are the statistics called (arithmetic) mean, median, and mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3esfQwOXx8sV"
   },
   "source": [
    "Mean could be for both, sample and population, but when we compute Sample Mean by the given formula, we are trying to estimate Population Mean. Formula for Population Mean is also same.\n",
    "\n",
    "**Sample Mean** $= \\bar{x} = \\frac{∑_{i=1} ^n x_i}{n}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZh0xb_l0HN7"
   },
   "source": [
    "In general, Mean is the \"Balance Point\". It becomes is the central point for particular cases (where distribution is symmetric). \\\\\n",
    "**Balance Point** is the point at which the total distance of all data points to the left equals the total distance to the right. This implies that Mean is affected by the **outliers**. The is no univarsal definition for outliers, but a general understanding is that data points which are far off from majority of data points are called outliers.  In physics terms, if each data point were a weight placed on a number line, the mean would be the point where the beam balances — like a seesaw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [2, 4, 6, 8, 10]\n",
    "mean_val = sum(data) / len(data)  # mean = 6\n",
    "\n",
    "# Distances from the mean\n",
    "left = [x - mean_val for x in data if x < mean_val]\n",
    "right = [x - mean_val for x in data if x > mean_val]\n",
    "\n",
    "print(f\"Total left distance:  {sum(left):.1f}\")\n",
    "print(f\"Total right distance: {sum(right):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnpBgiROqFBg"
   },
   "source": [
    "**Sample Mean** varies from sample to sample, probability distribution associated with sample mean is called **Sample Distribution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfZ9VVdJrjhz"
   },
   "source": [
    "**Median** is another measure of central tendency. It is the middle value after all the values are put in ordered list. If there are even number of values, take the average of the middle two values. Median need not to be unique, becuase the technical definition of Median is\n",
    "For a random variable $X$, $m$ is the Median if it satisfies the followig two inequalities -\n",
    "1.   $P(X<m) = 1/2$\n",
    "2.   $P(X>m) = 1/2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoT8jFQ2u7bm"
   },
   "source": [
    "For symmetric distributions, the Mean and the Median coincide. For unimodal skewed (asymmetric) distributions, the Mean is farther in the direction of the “pulled out tail” of the distribution than the Median is. This is becuase Mean is affected by the outliers and Median is not affected by the outliers. Therefore, for many cases of skewed distributions, the median is preferred as a measure of central tendency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCyouLnawrX7"
   },
   "source": [
    "A rarely used measure of central tendency is the **Mode**, which is the most likely or frequently occurring value $(x: x= argmax_{x_i} P(X=x_i))$\n",
    "\n",
    "In symmetric, unimodal distributions, the Mode equals both the Mean and the Median. In unimodal, skewed distributions the Mode is on the other side of the Median from the Mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, lognorm\n",
    "\n",
    "# Create figure with smaller size\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# ----- Case 1: Symmetric Unimodal (Standard Normal Distribution) -----\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "pdf_sym = norm.pdf(x, loc=0, scale=1)\n",
    "\n",
    "mean_sym = 0\n",
    "median_sym = 0\n",
    "mode_sym = 0\n",
    "\n",
    "axs[0].plot(x, pdf_sym, label='PDF', color='blue')\n",
    "axs[0].axvline(mean_sym, color='red', linestyle='--', label='Mean = Median = Mode')\n",
    "axs[0].set_title('Symmetric Unimodal (Normal)')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# ----- Case 2: Skewed Unimodal (Log-Normal) -----\n",
    "x = np.linspace(0, 5, 1000)\n",
    "data_skew = np.random.lognormal(mean=0, sigma=0.5, size=10000)\n",
    "pdf_skew = lognorm.pdf(x, s=0.5, scale=np.exp(0))\n",
    "\n",
    "mean_skew = np.mean(data_skew)\n",
    "median_skew = np.median(data_skew)\n",
    "mode_skew = np.exp(0 - 0.5**2)  # Mode of lognormal\n",
    "\n",
    "axs[1].plot(x, pdf_skew, label='PDF', color='blue')\n",
    "axs[1].axvline(mean_skew, color='red', linestyle='--', label='Mean')\n",
    "axs[1].axvline(median_skew, color='green', linestyle='--', label='Median')\n",
    "axs[1].axvline(mode_skew, color='orange', linestyle='--', label='Mode')\n",
    "axs[1].set_title('Skewed Unimodal (Log-Normal)')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeIIxM1Vz9-a"
   },
   "source": [
    "The most common measure of central tendency is the mean. For\n",
    "skewed distribution or when there is concern about outliers, the median may be preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAtULQaUz_94"
   },
   "source": [
    "## 1.6 Spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaDYsftq0TPX"
   },
   "source": [
    "Several statistics are commonly used as a measure of the spread of a distribution, including variance, standard deviation, and interquartile range. Spread is an indicator of how far away from the center we are still likely to ﬁnd data values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNW-6jS81Y6r"
   },
   "source": [
    "Variance is deﬁned as the mean squared deviation. Mathematically written as: \\\\\n",
    "**Population Variance** $= σ^2 = \\frac{(x_i - \\bar{x})}{N}$ Here $N$ is the population size. \\\\\n",
    "**Sample Variance** $= s^2 = \\frac{(x_i - \\bar{x})}{n-1}$ Here $n$ is the sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60jzFG9U4Kug"
   },
   "source": [
    " The sample formula for the variance of observed data conventionally\n",
    "has n−1 in the denominator instead of n to achieve the property of “unbiasedness”, which roughly means that when calculated for many diﬀerent random samples from the same population, the average should match the corresponding population quantity (i.e., $\\sigma^2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mapDmBZd4gxO"
   },
   "source": [
    "Because of the square, variances are always non-negative, and they have the somewhat unusual property of having squared units compared to the original data. So if the random variable of interest is a temperature in degrees, the variance has units “degrees squared”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXdT7Z2r5k_q"
   },
   "source": [
    "The **Standard Deviation** is simply the square root of the variance. Therefore it has the same units as the original data, which helps make it more interpretable. The sample standard deviation is usually represented by the symbol $s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcMVBHB66L46"
   },
   "source": [
    "Variances have the very important property that they are additive for any\n",
    "number of diﬀerent independent sources of variation. For example, the variance of a measurement which has subject-to-subject variability, environmental variability, and quality-of-measurement variability is equal to the sum of the three variances. \\\\\n",
    "This property is not shared by the Standard Deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOxdVkQM8GdW"
   },
   "source": [
    "A third measure of spread is the **Interquartile Range**. To deﬁne IQR, we\n",
    "ﬁrst need to deﬁne the concepts of quartiles. The quartiles of a population or a sample are the three values which divide the distribution or observed data into even fourths (represented by $Q1, Q2, Q3$).\n",
    "\n",
    "**IQR** $= Q3 - Q1$ and $Q2$ is the Median value.\n",
    "\n",
    "Range is the difference between maximum and minimum value, represented by - \\\\\n",
    "\n",
    "**Range** $= maximum - minimum$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9m-q9MB9BaR"
   },
   "source": [
    "## 1.7 Skewness and Kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-AwLHGd9HE7"
   },
   "source": [
    "**Skewness** is a measure of asymmetry. **Kurtosis** is a more subtle measure of peakedness compared to a Gaussian distribution. \\\\\n",
    "**Population Skewness** $= γ_1 = E[(\\frac{(X-μ)}{σ})^3] $ \\\\\n",
    "**Sample Skewness** $= b_1 = \\frac{m_3}{s^3} = \\frac{1/n ∑_{x_i =1} ^n (x_i - \\bar{x})^3}{[1/{n-1} ∑_{x_i =1} ^n (x_i - \\bar{x})^2]^{3/2}}$ \\\\\n",
    "**Population Kurtosis** $= κ = E[(\\frac{(X-μ)}{σ})^4] $ \\\\\n",
    "**Sample Kurtosis** $= b_2 = \\frac{m_4}{m_2 ^2} - 3 = \\frac{1/n ∑_{x_i =1} ^n (x_i - \\bar{x})^4}{[1/{n-1} ∑_{x_i =1} ^n (x_i - \\bar{x})^2]^2} - 3$ \\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLotjsAcKA3j"
   },
   "source": [
    "## 1.8 Univariate Graphical EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwFhxbMLKPo3"
   },
   "source": [
    "Non-graphical and graphical methods complement each other.\n",
    "While the non-graphical methods are quantitative and objective, they do not give a full picture of the data; therefore, graphical methods, which are more qualitative and involve a degree of subjective analysis, are also required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqnelkcAKsZw"
   },
   "source": [
    "# 1.8.1 Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXWHbC9xK2zB"
   },
   "source": [
    "The most basic graph is the histogram, which is a barplot in which each bar represents the frequency (count) or proportion (count/total count) of cases for a range of values. Generally values that fall exactly on the boundary between two bins are put in the lower bin, but this rule is not always followed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "# Load the data\n",
    "url = \"https://www.stat.cmu.edu/~hseltman/309/Book/data/EDA2.dat\"\n",
    "df = pd.read_csv(url, delim_whitespace=True)\n",
    "\n",
    "# Choose one of the numeric columns to plot\n",
    "column_to_plot = df.columns[0]  # Change to any column you want\n",
    "\n",
    "# Interactive histogram function\n",
    "def plot_histogram(bins):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(df[column_to_plot], bins=bins, edgecolor='black', color='skyblue')\n",
    "    plt.title(f'Histogram of {column_to_plot} with {bins} bins')\n",
    "    plt.xlabel(column_to_plot)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Create interactive slider for bins\n",
    "interact(plot_histogram, bins=IntSlider(min=5, max=50, step=1, value=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crgrVm12SMa-"
   },
   "source": [
    "With practice, histograms are one of the best ways to quickly learn\n",
    "a lot about your data, it gives qualitative understanding about central tendency, spread, modality, shape and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5jIqt_1SWSq"
   },
   "source": [
    "# 1.8.2 Stem-and-leaf Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIKM4QSjShHs"
   },
   "source": [
    "A simple substitute for a histogram is a stem and leaf plot. A stem and leaf plot is sometimes easier to make. Nevertheless, a histogram is generally considered better for appreciating the shape of a sample distribution than is the stem and leaf plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2Y3xSgRUk36"
   },
   "source": [
    "Stem | Leaves\n",
    "13   | 2\n",
    "14   | 5 7\n",
    "15   | 1\n",
    "16   | 2 8\n",
    "17   | 2 5\n",
    "18   | 1 3\n",
    "19   | 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKK22MwOU8Ry"
   },
   "source": [
    "### 🌿 Stem-and-Leaf Plot Example (Three-Digit Numbers)\n",
    "\n",
    "**Dataset:**\n",
    "132, 145, 147, 151, 162, 168, 172, 175, 181, 183, 199\n",
    "\n",
    "**Step 1: Sorted Data (already sorted)**\n",
    "\n",
    "**Step 2: Decide on Stem and Leaf**\n",
    "\n",
    "- **Stem** = First two digits (hundreds and tens)\n",
    "- **Leaf** = Last digit (units)\n",
    "\n",
    "**Step 3: Construct the Plot**\n",
    "\n",
    "Stem | Leaves \\\\\n",
    "13 | 2 \\\\\n",
    "14 | 5 7 <br>\n",
    "15 | 1 \\\\\n",
    "16 | 2 8 \\\\\n",
    "17 | 2 5 <br>\n",
    "18 | 1 3 \\\\\n",
    "19 | 9 \\\\\n",
    "\n",
    "\n",
    "**Key:**  \n",
    "`13 | 2` means **132**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWyBMmL_Vy7c"
   },
   "source": [
    "# 1.8.3 Boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhW0qy0_V3LB"
   },
   "source": [
    "Another very useful univariate graphical technique is the boxplot. Boxplots are very good at presenting information about the central tendency, symmetry and skew, as well as outliers, although they can be misleading about aspects such as multimodality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "url = \"https://www.stat.cmu.edu/~hseltman/309/Book/data/EDA2.dat\"\n",
    "df = pd.read_csv(url, delim_whitespace=True)\n",
    "\n",
    "# Choose the column to plot (e.g., first column)\n",
    "column = df.columns[0]\n",
    "data = df[column].dropna()  # Remove NaN if any\n",
    "\n",
    "# Calculate stats\n",
    "q1 = np.percentile(data, 25)\n",
    "q3 = np.percentile(data, 75)\n",
    "median = np.median(data)\n",
    "iqr = q3 - q1\n",
    "lower_whisker = max(min(data), q1 - 1.5 * iqr)\n",
    "upper_whisker = min(max(data), q3 + 1.5 * iqr)\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(3, 4))\n",
    "sns.boxplot(y=data, width=0.3, color='skyblue')\n",
    "\n",
    "# Annotate boxplot\n",
    "plt.text(1.05, median, 'Median', verticalalignment='center')\n",
    "plt.text(1.05, q1, 'Q1 (Lower hinge)', verticalalignment='center')\n",
    "plt.text(1.05, q3, 'Q3 (Upper hinge)', verticalalignment='center')\n",
    "plt.text(1.05, lower_whisker, 'Lower whisker end', verticalalignment='center')\n",
    "plt.text(1.05, upper_whisker, 'Upper whisker end', verticalalignment='center')\n",
    "plt.text(0.6, (q1 + q3) / 2, 'IQR', rotation=90, verticalalignment='center', fontsize=10)\n",
    "\n",
    "# Mark IQR with arrows\n",
    "plt.annotate('', xy=(0.7, q3), xytext=(0.7, q1), arrowprops=dict(arrowstyle='<->'))\n",
    "plt.text(0.72, (q1 + q3) / 2, 'IQR', verticalalignment='center')\n",
    "\n",
    "# Title and axis\n",
    "plt.title(f'Boxplot of {column} with Annotations')\n",
    "plt.ylabel(column)\n",
    "plt.xticks([])\n",
    "\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1I6e3_2edRW"
   },
   "source": [
    "**Important:** The term “outlier” is not well deﬁned in statistics, and the deﬁnition varies depending on the purpose and situation. The “outliers” identiﬁed by a boxplot, which could be called “boxplot outliers” are deﬁned as any points more than 1.5 IQRs above Q3 or more than 1.5 IQRs below Q1. This *does not* by itself indicate a problem with those data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHNgJRMuenGO"
   },
   "source": [
    "The term **fat tails** is used to describe the situation where a histogram has a lot of values far from the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EKvEWCkfcCW"
   },
   "source": [
    "# 1.8.4 Quantile-normal plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcZD-SqufkpZ"
   },
   "source": [
    "It is used to see how well a particular sample follows a particular\n",
    "theoretical distribution. Although it can be used for any theoretical distribution, we will limit our attention to Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tt2--0ugG-k"
   },
   "source": [
    "✅ Steps to Construct a Q–Q Plot:\n",
    "1.   Sort the sample data in ascending order.\n",
    "2.   Compute theoretical quantiles from a reference distribution (e.g., normal).\n",
    "3. Plot the sample quantiles (y-axis) vs. theoretical quantiles (x-axis) \\\\\n",
    "4.  Check linearity: \\\\\n",
    "    If the points lie close to a straight line → data follows the reference distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Step 1: Load and select data\n",
    "url = \"https://www.stat.cmu.edu/~hseltman/309/Book/data/EDA2.dat\"\n",
    "df = pd.read_csv(url, delim_whitespace=True)\n",
    "\n",
    "# We'll use the first numeric column\n",
    "data = df[df.columns[0]].dropna()\n",
    "data_sorted = np.sort(data)\n",
    "\n",
    "# Step 2: Compute theoretical quantiles from a normal distribution\n",
    "n = len(data_sorted)\n",
    "theoretical_quantiles = stats.norm.ppf((np.arange(1, n + 1) - 0.5) / n)\n",
    "\n",
    "# Step 3: Plot the Q–Q plot manually\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(theoretical_quantiles, data_sorted, color='blue', label='Data Points')\n",
    "\n",
    "# Step 4: Reference line (ideal match if normally distributed)\n",
    "slope, intercept = np.polyfit(theoretical_quantiles, data_sorted, 1)\n",
    "plt.plot(theoretical_quantiles, slope * theoretical_quantiles + intercept, color='red', label='Reference Line')\n",
    "\n",
    "# Plot formatting\n",
    "plt.title('Q–Q Plot (Sample vs. Normal Distribution)')\n",
    "plt.xlabel('Theoretical Quantiles (Normal)')\n",
    "plt.ylabel('Sample Quantiles')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define data types\n",
    "np.random.seed(1)\n",
    "data_normal = np.random.normal(0, 1, 1000)\n",
    "data_right_skew = np.random.exponential(scale=1, size=1000)\n",
    "data_left_skew = -np.random.exponential(scale=1, size=1000)\n",
    "data_heavy_tailed = np.random.standard_t(df=2, size=1000)\n",
    "data_light_tailed = np.random.uniform(-1, 1, 1000)\n",
    "\n",
    "# Titles and comments\n",
    "data_list = [\n",
    "    (data_normal, \"Normal Data\", \"✅ Points fall along the line → normal distribution\"),\n",
    "    (data_right_skew, \"Right-Skewed Data\", \"📈 Right tail rises above the line\"),\n",
    "    (data_left_skew, \"Left-Skewed Data\", \"📉 Left tail falls below the line\"),\n",
    "    (data_heavy_tailed, \"Heavy-Tailed Data (t-dist)\", \"🚩 Tails diverge far from the line\"),\n",
    "    (data_light_tailed, \"Light-Tailed Data (Uniform)\", \"🔍 Points curve inward → too short tails\"),\n",
    "]\n",
    "\n",
    "# Plot setup\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, (data, title, comment) in enumerate(data_list, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    stats.probplot(data, dist=\"norm\", plot=plt)\n",
    "    plt.title(title, fontsize=10)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.text(0.05, 0.9, comment, transform=plt.gca().transAxes, fontsize=8, bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "plt.suptitle(\"Q–Q Plots: Good Fit vs Bad Fit Cases\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKn3qbXsp5NR"
   },
   "source": [
    "## 1.9 Multivariate non-graphical EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Csq4QuQExLDd"
   },
   "source": [
    "Multivariate non-graphical EDA techniques generally show the relationship between two or more variables in the form of either cross-tabulation or statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pL_ncSTGxTVW"
   },
   "source": [
    "# 1.9.1 Cross-tabulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zdw_yMC4xYhZ"
   },
   "source": [
    "For categorical data (and quantitative data with only a few diﬀerent values) an extension of tabulation called cross-tabulation is very useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-DRQscK0wyo"
   },
   "source": [
    "### Table 4.1: Sample Data for Cross-tabulation\n",
    "\n",
    "| Subject ID | Age Group | Sex |\n",
    "|------------|-----------|-----|\n",
    "| GW         | young     | F   |\n",
    "| JA         | middle    | F   |\n",
    "| TJ         | young     | M   |\n",
    "| JMA        | young     | M   |\n",
    "| JMO        | middle    | F   |\n",
    "| JQA        | old       | F   |\n",
    "| AJ         | old       | F   |\n",
    "| MVB        | young     | M   |\n",
    "| WHH        | old       | F   |\n",
    "| JT         | young     | F   |\n",
    "| JKP        | middle    | M   |\n",
    "\n",
    "---\n",
    "\n",
    "### Table 4.2: Cross-tabulation of Sample Data\n",
    "\n",
    "| Age Group / Sex | Female | Male | Total |\n",
    "|------------------|--------|------|--------|\n",
    "| young            | 2      | 3    | 5      |\n",
    "| middle           | 2      | 1    | 3      |\n",
    "| old              | 3      | 0    | 3      |\n",
    "| **Total**        | 7      | 4    | 11     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hX2OHvp0zky"
   },
   "source": [
    "## 1.9.2 Correlation for categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1L6FXbD1M5S"
   },
   "source": [
    "Another statistic that can be calculated for two categorical variables is their correlation. But there are many forms of correlation for categorical variables, and that material is currently beyond the scope and will be studied later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pjXFZUs1X5D"
   },
   "source": [
    "# 1.9.3 Univariate statistics by category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgKXTAhwKxfQ"
   },
   "source": [
    "For one categorical variable (usually explanatory) and one quantitative variable (usually outcome), it is common to produce some of the standard univariate non-graphical statistics for the quantitative variables separately for each level of the categorical variable, and then compare the statistics across levels of the categorical variable. Comparing the means is an informal version of ANOVA. Comparing medians is a robust informal version of one-way ANOVA. Comparing measures of spread is a good informal test of the assumption of equal variances needed for valid analysis of variance.\n",
    "\n",
    "Especially for a categorical explanatory variable and a quantitative\n",
    "outcome variable, it is useful to produce a variety of univariate statis-\n",
    "tics for the quantitative variable at each level of the categorical vari-\n",
    "able."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MU2HOZnCK9Sd"
   },
   "source": [
    "# 1.9.4 Correlation and covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-P6MLMxLi9D"
   },
   "source": [
    "For two quantitative variables, the basic statistics of interest are the sample co-variance and/or sample correlation.\n",
    "\n",
    "The sample covariance is a measure of how much two variables “co-vary”, i.e., how much (and in what direction) should we expect one variable to change when the other changes.\n",
    "\n",
    "### 📐 Sample Covariance Formula\n",
    "\n",
    "The formula for **sample covariance** between two variables \\( X \\) and \\( Y \\) is:\n",
    "$\n",
    "[\n",
    "\\text{Cov}(X, Y) = \\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})\n",
    "]\n",
    "$\n",
    "Where:\n",
    "- $( n )$ is the number of observations  \n",
    "- $( x_i, y_i )$ are the individual sample points  \n",
    "- $( \\bar{x}, \\bar{y} )$ are the sample means of $( X )$ and $( Y )$ respectively.\n",
    "\n",
    "Positive covariance values suggest that when one measurement is above the\n",
    "mean the other will probably also be above the mean, and vice versa. Negative covariances suggest that when one variable is above its mean, the other is below its mean. And covariances near zero suggest that the two variables vary independently of each other.\n",
    "\n",
    "**Important**: Technically, independence implies zero correlation, but the reverse is not necessarily true.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ENfJDOXNERT"
   },
   "source": [
    "Covariances tend to be hard to interpret, so we often use correlation instead. The correlation has the nice property that it is always between -1 and +1, with -1 being a “perfect” negative linear correlation, +1 being a perfect positive linear correlation and 0 indicating that $X$ and $Y$ are uncorrelated. The symbol $r$ or $r_{x,y}$ is often used for sample correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sADA1cY8OMpn"
   },
   "source": [
    "### 📊 Table 4.3: Covariance Sample Data\n",
    "\n",
    "| Subject ID | Age | Strength |\n",
    "|------------|-----|----------|\n",
    "| GW         | 38  | 20       |\n",
    "| JA         | 62  | 15       |\n",
    "| TJ         | 22  | 30       |\n",
    "| JMA        | 38  | 21       |\n",
    "| JMO        | 45  | 18       |\n",
    "| JQA        | 69  | 12       |\n",
    "| AJ         | 75  | 14       |\n",
    "| MVB        | 38  | 28       |\n",
    "| WHH        | 80  | 9        |\n",
    "| JT         | 32  | 22       |\n",
    "| JKP        | 51  | 20       |\n",
    "\n",
    "---\n",
    "\n",
    "### 🧮 Step-by-Step Computation\n",
    "\n",
    "**Step 1: Compute Means**\n",
    "$\n",
    "[\n",
    "\\bar{X} = \\text{Mean of Age} = \\frac{38 + 62 + \\dots + 51}{11} = \\frac{550}{11} = 50.0\n",
    "]\n",
    "$ $\n",
    "[\n",
    "\\bar{Y} = \\text{Mean of Strength} = \\frac{20 + 15 + \\dots + 20}{11} = \\frac{209}{11} \\approx 19.0\n",
    "]\n",
    "$\n",
    "---\n",
    "\n",
    "**Step 2: Compute Deviations and Product of Deviations**\n",
    "\n",
    "| Subject | \\( X_i - \\bar{X} \\) | \\( Y_i - \\bar{Y} \\) | Product |\n",
    "|---------|----------------------|----------------------|---------|\n",
    "| GW      | -12.0               | 1.0                 | -12.0   |\n",
    "| JA      | 12.0                | -4.0                | -48.0   |\n",
    "| TJ      | -28.0               | 11.0                | -308.0  |\n",
    "| JMA     | -12.0               | 2.0                 | -24.0   |\n",
    "| JMO     | -5.0                | -1.0                | 5.0     |\n",
    "| JQA     | 19.0                | -7.0                | -133.0  |\n",
    "| AJ      | 25.0                | -5.0                | -125.0  |\n",
    "| MVB     | -12.0               | 9.0                 | -108.0  |\n",
    "| WHH     | 30.0                | -10.0               | -300.0  |\n",
    "| JT      | -18.0               | 3.0                 | -54.0   |\n",
    "| JKP     | 1.0                 | 1.0                 | 1.0     |\n",
    "\n",
    "Sum of products = **-1106.0**\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Compute Sample Covariance**\n",
    "\n",
    "$[\n",
    "\\text{Cov}(X, Y) = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{n - 1} = \\frac{-1106}{10} = -110.6\n",
    "]$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 4: Compute Standard Deviations**\n",
    "\n",
    "- $( s_X = \\sqrt{\\frac{\\sum (X_i - \\bar{X})^2}{n - 1}} \\approx 18.63 )$  \n",
    "- $( s_Y = \\sqrt{\\frac{\\sum (Y_i - \\bar{Y})^2}{n - 1}} \\approx 6.82 )$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 5: Compute Correlation Coefficient**\n",
    "\n",
    "$[\n",
    "r = \\frac{\\text{Cov}(X, Y)}{s_X s_Y} = \\frac{-110.6}{(18.63)(6.82)} \\approx \\frac{-110.6}{127.1} \\approx -0.87\n",
    "]$\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Final Results:\n",
    "\n",
    "- **Sample Covariance** = **–110.6**  \n",
    "- **Sample Correlation** = **–0.87** (strong negative relationship)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8wj_e_uO_uD"
   },
   "source": [
    "When we have many quantitative variables the most common non-graphical EDA\n",
    "technique is to calculate all of the **Pairwise Covariances and/or Correlations** and assemble them into a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpcmWau-WMQh"
   },
   "source": [
    "### 📊 Table 4.4: Covariance Calculation\n",
    "\n",
    "| Subject ID | Age | Strength | Age - 50 | Str - 19 | Product |\n",
    "|------------|-----|----------|----------|----------|---------|\n",
    "| GW         | 38  | 20       | -12      | +1       | -12     |\n",
    "| JA         | 62  | 15       | +12      | -4       | -48     |\n",
    "| TJ         | 22  | 30       | -28      | +11      | -308    |\n",
    "| JMA        | 38  | 21       | -12      | +2       | -24     |\n",
    "| JMO        | 45  | 18       | -5       | -1       | +5      |\n",
    "| JQA        | 69  | 12       | +19      | -7       | -133    |\n",
    "| AJ         | 75  | 14       | +25      | -5       | -125    |\n",
    "| MVB        | 38  | 28       | -12      | +9       | -108    |\n",
    "| WHH        | 80  | 9        | +30      | -10      | -300    |\n",
    "| JT         | 32  | 22       | -18      | +3       | -54     |\n",
    "| JKP        | 51  | 20       | +1       | +1       | +1      |\n",
    "| **Total**  |     |          | **0**    | **0**    | **-1106** |\n",
    "\n",
    "---\n",
    "\n",
    "### 🧮 Table 4.5: A Covariance Matrix\n",
    "\n",
    "|       | X    | Y    | Z    |\n",
    "|-------|------|------|------|\n",
    "| **X** | 5.00 | 1.77 | -2.24 |\n",
    "| **Y** | 1.77 | 7.0  | 3.17  |\n",
    "| **Z** | -2.24| 3.17 | 4.0   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkiA8kbZWR_m"
   },
   "source": [
    "## 1.9.4 Multivariate Graphical EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wOtkrueXGNg"
   },
   "source": [
    "When we have one categorical (usually explanatory) and one quantitative (usually outcome) variable, graphical EDA usually takes the form of “conditioning” on the categorical random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "url = \"https://www.stat.cmu.edu/~hseltman/309/Book/data/EDA3.dat\"\n",
    "df = pd.read_csv(url, sep='\\s+')\n",
    "\n",
    "# Display the first few rows to understand the data\n",
    "print(df.head())\n",
    "\n",
    "# Step 1: Create Age Group bins\n",
    "bins = [21, 42, 62, 82]\n",
    "labels = [\"(21,42]\", \"(42,62]\", \"(62,82]\"]\n",
    "df[\"Age Group\"] = pd.cut(df[\"Age\"], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Step 2: Create the boxplot\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.boxplot(x=\"Age Group\", y=\"Strength\", data=df, width=0.6)\n",
    "\n",
    "# Step 3: Customize plot\n",
    "plt.title(\"Side-by-side Boxplot of EDA3.dat\", fontsize=12)\n",
    "plt.ylabel(\"Strength\", fontsize=12)\n",
    "plt.xlabel(\"Age Group\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbQaC7qOXbC2"
   },
   "source": [
    "For two quantitative variables, the basic graphical EDA technique is the scatterplot which has one variable on the x-axis, one on the y-axis and a point for each case in your dataset. If one variable is explanatory and the other is outcome, it is a very, very strong convention to put the outcome on the y (vertical) axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "url = \"https://www.stat.cmu.edu/~hseltman/309/Book/data/EDA3.dat\"\n",
    "df = pd.read_csv(url, sep=\"\\s+\")\n",
    "\n",
    "# Define color and marker by Sex/Party combination\n",
    "def color_marker(row):\n",
    "    if row[\"Sex\"] == \"F\" and row[\"Party\"] == \"Dem\":\n",
    "        return (\"blue\", \"^\")   # triangle, blue\n",
    "    elif row[\"Sex\"] == \"F\" and row[\"Party\"] == \"Rep\":\n",
    "        return (\"red\", \"^\")    # triangle, red\n",
    "    elif row[\"Sex\"] == \"M\" and row[\"Party\"] == \"Dem\":\n",
    "        return (\"blue\", \"o\")   # circle, blue\n",
    "    elif row[\"Sex\"] == \"M\" and row[\"Party\"] == \"Rep\":\n",
    "        return (\"red\", \"o\")    # circle, red\n",
    "\n",
    "# Add color and marker columns\n",
    "df[[\"Color\", \"Marker\"]] = df.apply(color_marker, axis=1, result_type='expand')\n",
    "\n",
    "# Create plot\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    plt.scatter(row[\"Age\"], row[\"Strength\"], color=row[\"Color\"], marker=row[\"Marker\"], s=60)\n",
    "\n",
    "# Custom legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='^', color='w', markerfacecolor='blue', markersize=10, label='F/Dem'),\n",
    "    Line2D([0], [0], marker='^', color='w', markerfacecolor='red', markersize=10, label='F/Rep'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='M/Dem'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='M/Rep'),\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "# Labels\n",
    "plt.xlabel(\"Age\", fontsize=12)\n",
    "plt.ylabel(\"Strength\", fontsize=12)\n",
    "plt.title(\"Strength vs Age by Sex and Party\", fontsize=13)\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
